{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competitive Intelligence Dashboard\n",
    "\n",
    "Automated competitor analysis using LLM workflows.\n",
    "\n",
    "**Day 5 Concepts:** Multi-step LLM workflows, structured JSON outputs, content aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "from scraper import fetch_website_links, fetch_website_contents\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "MODEL = 'gpt-5-nano'\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competitive Intelligence Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompetitiveIntelligence:\n",
    "    \"\"\"\n",
    "    Analyzes competitor websites and generates intelligence reports\n",
    "    Day 5 concepts: Multi-step LLM workflows, structured outputs, content aggregation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model: str = \"gpt-5-nano\"):\n",
    "        self.model = model\n",
    "        \n",
    "        # System prompt for link selection (Day 5 pattern)\n",
    "        self.link_system_prompt = \"\"\"\n",
    "        You are provided with a list of links from a competitor website.\n",
    "        Select links relevant for competitive analysis:\n",
    "        - Product pages\n",
    "        - Pricing pages\n",
    "        - About/Company pages\n",
    "        - Feature pages\n",
    "        - Case studies\n",
    "        Do not include: Terms of Service, Privacy, email links.\n",
    "        Respond in JSON format:\n",
    "        {\n",
    "            \"links\": [\n",
    "                {\"type\": \"product page\", \"url\": \"https://...\"},\n",
    "                {\"type\": \"pricing page\", \"url\": \"https://...\"}\n",
    "            ]\n",
    "        }\n",
    "        \"\"\"\n",
    "        \n",
    "        # System prompt for data extraction (Day 5 pattern)\n",
    "        self.extraction_system_prompt = \"\"\"\n",
    "        You are analyzing a competitor company website.\n",
    "        Extract key competitive intelligence:\n",
    "        - Company name\n",
    "        - Products/services\n",
    "        - Key features\n",
    "        - Pricing information (if available)\n",
    "        - Target market\n",
    "        - Unique selling points\n",
    "        - Company positioning\n",
    "        \n",
    "        Respond in JSON format:\n",
    "        {\n",
    "            \"company_name\": \"...\",\n",
    "            \"products\": [\n",
    "                {\"name\": \"...\", \"description\": \"...\", \"features\": [...]}\n",
    "            ],\n",
    "            \"pricing_info\": \"...\",\n",
    "            \"target_market\": \"...\",\n",
    "            \"key_features\": [...],\n",
    "            \"positioning\": \"...\"\n",
    "        }\n",
    "        \"\"\"\n",
    "    \n",
    "    def get_links_user_prompt(self, url: str) -> str:\n",
    "        \"\"\"Build prompt for link selection (Day 5 pattern)\"\"\"\n",
    "        user_prompt = f\"\"\"\n",
    "        Here are links from competitor website {url}\n",
    "        Select links relevant for competitive analysis (products, pricing, features).\n",
    "        Respond with full https URLs in JSON format.\n",
    "        \n",
    "        Links:\n",
    "        \"\"\"\n",
    "        links = fetch_website_links(url)\n",
    "        user_prompt += \"\\n\".join(links)\n",
    "        return user_prompt\n",
    "    \n",
    "    def select_relevant_links(self, url: str) -> dict:\n",
    "        \"\"\"Select relevant links for analysis (Day 5 pattern)\"\"\"\n",
    "        response = openai.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.link_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": self.get_links_user_prompt(url)}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        result = json.loads(response.choices[0].message.content)\n",
    "        return result\n",
    "    \n",
    "    def extract_competitor_data(self, url: str) -> dict:\n",
    "        \"\"\"Extract structured competitor data (Day 5 pattern)\"\"\"\n",
    "        # Step 1: Get landing page content\n",
    "        landing_content = fetch_website_contents(url)\n",
    "        \n",
    "        # Step 2: Select relevant links\n",
    "        relevant_links = self.select_relevant_links(url)\n",
    "        \n",
    "        # Step 3: Aggregate content (Day 5 pattern)\n",
    "        aggregated_content = f\"## Landing Page:\\n\\n{landing_content}\\n## Key Pages:\\n\"\n",
    "        for link in relevant_links.get('links', []):\n",
    "            try:\n",
    "                page_content = fetch_website_contents(link[\"url\"])\n",
    "                aggregated_content += f\"\\n\\n### {link['type']}:\\n{page_content}\"\n",
    "            except Exception as e:\n",
    "                aggregated_content += f\"\\n\\n### {link['type']}:\\n(Error fetching: {str(e)})\"\n",
    "        \n",
    "        # Step 4: Extract structured data (Day 5 pattern)\n",
    "        response = openai.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.extraction_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": aggregated_content}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        \n",
    "        result = json.loads(response.choices[0].message.content)\n",
    "        result['url'] = url\n",
    "        return result\n",
    "    \n",
    "    def compare_competitors(self, competitor_urls: list, your_company_url: str = None) -> dict:\n",
    "        \"\"\"Compare multiple competitors (Day 5 pattern)\"\"\"\n",
    "        print(f\"Analyzing {len(competitor_urls)} competitors...\")\n",
    "        \n",
    "        # Extract data from each competitor\n",
    "        competitor_data = []\n",
    "        for url in competitor_urls:\n",
    "            print(f\"Processing {url}...\")\n",
    "            try:\n",
    "                data = self.extract_competitor_data(url)\n",
    "                competitor_data.append(data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error analyzing {url}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Get your company data if provided\n",
    "        your_company_data = None\n",
    "        if your_company_url:\n",
    "            print(f\"Processing your company: {your_company_url}...\")\n",
    "            try:\n",
    "                your_company_data = self.extract_competitor_data(your_company_url)\n",
    "            except Exception as e:\n",
    "                print(f\"Error analyzing your company: {e}\")\n",
    "        \n",
    "        # Generate comparison report\n",
    "        comparison_system_prompt = \"\"\"\n",
    "        You are a competitive intelligence analyst.\n",
    "        Compare multiple competitors and provide insights.\n",
    "        Create a comprehensive competitive analysis report in markdown format.\n",
    "        Include:\n",
    "        - Feature comparison matrix\n",
    "        - Pricing comparison\n",
    "        - Market positioning analysis\n",
    "        - Strengths and weaknesses\n",
    "        - Competitive gaps and opportunities\n",
    "        \"\"\"\n",
    "        \n",
    "        comparison_data = {\n",
    "            \"competitors\": competitor_data\n",
    "        }\n",
    "        if your_company_data:\n",
    "            comparison_data[\"your_company\"] = your_company_data\n",
    "        \n",
    "        user_prompt = f\"\"\"\n",
    "        Analyze and compare these competitors:\n",
    "        \n",
    "        {json.dumps(comparison_data, indent=2)}\n",
    "        \n",
    "        Generate a comprehensive competitive intelligence report.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = openai.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": comparison_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"report\": response.choices[0].message.content,\n",
    "            \"competitor_data\": competitor_data,\n",
    "            \"your_company_data\": your_company_data\n",
    "        }\n",
    "    \n",
    "    def generate_report(self, competitor_urls: list, your_company_url: str = None):\n",
    "        \"\"\"Generate and display competitive intelligence report\"\"\"\n",
    "        comparison = self.compare_competitors(competitor_urls, your_company_url)\n",
    "        display(Markdown(comparison[\"report\"]))\n",
    "        return comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Analyze Single Competitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company: Hugging Face\n",
      "Products: 6\n",
      "Key Features: ['Open-source ML hub to host, discover, and experiment with models, datasets, and Spaces', '2M+ models and datasets catalog', 'Multi-modal support (text, image, video, audio, 3D)']\n"
     ]
    }
   ],
   "source": [
    "# Initialize analyzer\n",
    "analyzer = CompetitiveIntelligence()\n",
    "\n",
    "# Analyze single competitor\n",
    "competitor_data = analyzer.extract_competitor_data(\"https://huggingface.co\")\n",
    "\n",
    "# Display results\n",
    "print(f\"Company: {competitor_data.get('company_name')}\")\n",
    "print(f\"Products: {len(competitor_data.get('products', []))}\")\n",
    "print(f\"Key Features: {competitor_data.get('key_features', [])[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Compare Multiple Competitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 2 competitors...\n",
      "Processing https://huggingface.co...\n",
      "Processing https://anthropic.com...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Competitive Intelligence Report\n",
       "Hugging Face vs Anthropic\n",
       "Scope: Comparative analysis of the given Hugging Face suite and Anthropic offerings, focusing on product features, pricing, market positioning, strengths/weaknesses, and strategic gaps/opportunities.\n",
       "\n",
       "Date: 2026-02-17\n",
       "\n",
       "1) Executive summary\n",
       "- Hugging Face excels as an open, collaboration-first platform with strong emphasis on open-source ethos, model/dataset hosting, and centralized, managed deployment options (Inference Endpoints, Spaces). It also targets enterprises with governance and security features (Enterprise Hub) plus scalable compute and private data capabilities.\n",
       "- Anthropic positions Claude and its extended ecosystem around safety, reliability, and enterprise-grade workflows. It emphasizes agent-enabled coding and knowledge-work, deep integrations with common tools, and a Developer Platform to build on top of Claude across cloud environments. Lulu: pricing is token-based for core models, plus subscription tiers (Max, Team, Enterprise) for scale and governance.\n",
       "- Competitive takeaway: Hugging Face dominates collaboration, model/dataset management, and multi-modality in an open ecosystem with strong enterprise governance. Anthropic dominates safety, reliability, developer tooling, and enterprise-ready deployments with strong governance and cross-cloud reach. The main gaps/choices revolve around governance depth, data residency, on-prem capabilities, cost models, and the breadth of agent-centric workflows.\n",
       "\n",
       "2) Market positioning at a glance\n",
       "- Hugging Face\n",
       "  - Positioning: The leading open, community-driven AI platform that merges collaborative ML with enterprise-grade security and managed compute. Focused on rapid collaboration, deployment, and scaling of models, datasets, and interactive apps (Spaces).\n",
       "  - Target markets: Individual developers/researchers, small-to-mid teams, and large enterprises seeking open-source collaboration with enterprise-grade deployment, security, and governance.\n",
       "- Anthropic\n",
       "  - Positioning: Safety-first, reliability-first AI designed for enterprise-grade workflows, coding, and agent-driven tasks. Emphasizes governance, privacy, and safe/interpretability-focused AI with a Developer Platform to build and scale across organizations.\n",
       "  - Target markets: Business teams, developers, and large enterprises across customer support, education, finance, government, healthcare, life sciences, nonprofits; organizations requiring safety, auditability, and scalable AI workflows.\n",
       "\n",
       "3) Feature comparison matrix (selected capabilities)\n",
       "Note: This matrix evaluates core capabilities across Hugging Face’s four primary products and Anthropic’s main offerings. “✓” indicates strong coverage, “Partial” indicates partial/limited coverage, “No” indicates not primarily supported, and “N/A” indicates not applicable within the product’s scope.\n",
       "\n",
       "- Key:\n",
       "  - Hub = Hugging Face Hub\n",
       "  - Endpoints = Inference Endpoints\n",
       "  - Spaces = Spaces\n",
       "  - Enterprise Hub = Enterprise Hub (Team/Enterprise)\n",
       "  - Claude family = Anthropic Claude and related products\n",
       "  - Platform = Claude Developer Platform\n",
       "\n",
       "Capability area | Hub | Endpoints | Spaces | Enterprise Hub | Claude | Claude Code | Cowork | Claude Developer Platform | Claude Opus 4.6 | Claude Sonnet 4.5 | Claude Haiku 4.5 | Max plan | Team plan | Enterprise plan\n",
       "---|---|---|---|---|---|---|---|---|---|---|---|---|---|---\n",
       "Open-source model/dataset hosting | ✓ | N/A | N/A | ✓ (private datasets, governance) | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A\n",
       "Git-based collaboration / versioning | ✓ | N/A | N/A | ✓ | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A\n",
       "Public & private models/datasets | ✓ (public/private) | N/A | N/A | ✓ | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A\n",
       "Datasets viewer / data tooling | ✓ (datasets viewer) | N/A | N/A | ✓ | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A\n",
       "Multi-modality support | ✓ (text, image, video, audio, 3D) | N/A | N/A | ✓ | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A\n",
       "Managed deployment / one-click deployment | N/A | ✓ | N/A | ✓ | N/A | N/A | N/A | ✓ | N/A | N/A | N/A | N/A | N/A | N/A\n",
       "Autoscaling / pay-per-use compute | ✓ (via compute options) | ✓ (per-minute pricing) | N/A | ✓ | N/A | N/A | N/A | ✓ (API-based) | N/A | N/A | N/A | N/A | N/A | N/A\n",
       "Observability / logs & metrics | ✓ | ✓ | N/A | ✓ | N/A | N/A | N/A | ✓ | N/A | N/A | N/A | N/A | N/A | N/A\n",
       "Secure access to model weights / private access | ✓ | N/A | N/A | ✓ | N/A | N/A | N/A | ✓ | N/A | N/A | N/A | N/A | N/A | N/A\n",
       "Single Sign-On (SSO) / SAML | ✓ | N/A | N/A | ✓ | N/A | N/A | N/A | ✓ | N/A | N/A | N/A | N/A | N/A | N/A\n",
       "Audit logs / governance / policy mgmt | ✓ | N/A | N/A | ✓ | N/A | N/A | N/A | ✓ | N/A | N/A | N/A | N/A | N/A | N/A\n",
       "Private storage / regional data controls | ✓ | N/A | N/A | ✓ (region selection) | N/A | N/A | N/A | ✓ | N/A | N/A | N/A | N/A | N/A | N/A\n",
       "Advanced compute options / GPUs | ✓ | N/A | N/A | ✓ | N/A | N/A | N/A | ✓ | N/A | N/A | N/A | N/A | N/A | N/A\n",
       "APIs for model deployment | ✓ | ✓ | N/A | ✓ | ✓ (API) | N/A | N/A | ✓ | N/A | N/A | N/A | N/A | N/A | N/A\n",
       "Developer tooling / platform access | ✓ (ecosystem docs) | N/A | N/A | ✓ | ✓ (Claude Developer Platform) | ✓(for coding) | N/A | ✓ | N/A | N/A | N/A | N/A | N/A | N/A\n",
       "\n",
       "Notes:\n",
       "- Hugging Face products are organized as a portfolio: Hub (hosting/collaboration), Inference Endpoints (production deployment), Spaces (interactive apps), and Enterprise Hub (security/governance/SSO/audit). The table shows coverage where clearly stated in the provided data. Spaces emphasizes zero-GPU hosting and multi-modal app hosting.\n",
       "- Anthropic products span Claude across general-use, coding, desktop integration, and developer tooling (Claude Developer Platform), plus long-context capabilities in Opus, Sonnet, Haiku variants, and enterprise/team plans with governance metrics.\n",
       "\n",
       "2b) Pricing comparison (high level)\n",
       "- Hugging Face\n",
       "  - Hub/Enterprise: Pricing tiers include PRO (~$9 per user/month), Team (~$20 per user/month), and Enterprise (~$50+ per user/month) with custom onboarding and contract options.\n",
       "  - Inference Endpoints: Self-serve pay-as-you-go pricing (per-minute usage). Rates vary by engine and configuration.\n",
       "  - Notes: The pricing model emphasizes per-user subscriptions for collaboration/enterprise features and usage-based pricing for production deployments.\n",
       "- Anthropic\n",
       "  - Claude Opus 4.6: Starts at $5 per 1,000,000 input tokens and $25 per 1,000,000 output tokens; savings up to 90% via prompt caching; up to 50% via batch processing.\n",
       "  - Claude Sonnet 4.5: Starts at $3 per 1,000,000 input tokens and $15 per 1,000,000 output tokens; similar savings mechanisms.\n",
       "  - Claude Haiku 4.5: Starts at $1 per 1,000,000 input tokens and $5 per 1,000,000 output tokens; lower-cost option optimized for latency-sensitive use.\n",
       "  - Max plan: Bundles Claude desktop/mobile apps with Claude Code and promises up to 20x more usage per session than Pro.\n",
       "  - Team plan: For collaboration across teams; productivity gains cited.\n",
       "  - Enterprise plan: Secure, enterprise-grade deployments with governance and scalable deployment; enterprise metrics (broad adoption, agents deployed, etc.) cited.\n",
       "  - Notes: Token-based pricing with volume discounts via prompt caching and batch processing; multiple plan tiers catering to individuals, teams, and enterprises; cross-cloud availability implied.\n",
       "\n",
       "3) Market positioning: deeper analysis\n",
       "- Hugging Face\n",
       "  - Core value proposition: Open-source, collaborative ML with centralized hosting (models, datasets, Spaces) and managed production options. Emphasis on community, transparency, and rapid experimentation with governance for teams/enterprises.\n",
       "  - Competitive edge: Largest emphasis on multi-modal, open weights/datasets, and a broad ecosystem enabling rapid iteration and sharing. Enterprise Hub adds governance, SSO, private data, and audit capabilities to meet enterprise needs.\n",
       "  - Risks/constraints: If enterprise buyers prioritize strict data residency, on-prem deployments, or highly specialized safety controls beyond governance tooling, Hugging Face may need deeper capabilities or partnerships to meet those requirements.\n",
       "- Anthropic\n",
       "  - Core value proposition: Safety-first, reliable AI with robust developer tooling and enterprise-grade deployment. Emphasizes agentivity, long-context capabilities, and deep integrations with common productivity tools (Chrome, Slack, Excel, PowerPoint).\n",
       "  - Competitive edge: Strong focus on safety, interpretability, and governance; a breadth of Claude variants tailored for coding, agents, and enterprise workflows; cross-cloud availability via the Claude Developer Platform.\n",
       "  - Risks/constraints: Token-based pricing can be a barrier at scale if usage is heavy; dependency on token economics may affect cost predictability; market perception of safety features vs. speed/cost tradeoffs for some use cases.\n",
       "\n",
       "4) Strengths and weaknesses (high-signal)\n",
       "- Hugging Face\n",
       "  - Strengths\n",
       "    - Open-source, community-driven; vast ecosystem of models, datasets, and Spaces.\n",
       "    - Strong collaboration tooling with Git-based workflows and private data governance options.\n",
       "    - Flexible deployment options (Hub, Inference Endpoints, Spaces) with multi-modality support.\n",
       "    - Enterprise governance features (SSO, SAML, audit logs, policy management) and private data handling.\n",
       "  - Weaknesses\n",
       "    - Production-scale safety/compliance features may be less prescriptive than a safety-first vendor’s core offering.\n",
       "    - Token-based pricing for production endpoints can be cost-uncertain without clear usage patterns.\n",
       "    - On-prem or fully isolated data residency options are not explicitly detailed in the provided data (though region storage is mentioned in Enterprise Hub).\n",
       "\n",
       "- Anthropic\n",
       "  - Strengths\n",
       "    - Safety-first, reliability, interpretability, and steerability baked into design.\n",
       "    - Broad developer tooling (Claude Developer Platform) and multi-modal capabilities across coding, agents, and enterprise workflows.\n",
       "    - Strong enterprise sentiment with governance metrics and cross-cloud availability (Bedrock/Vertex/Foundry compatibility).\n",
       "    - Long-context capabilities (Opus 4.6) enabling sophisticated agent reasoning and coding workflows.\n",
       "  - Weaknesses\n",
       "    - Token-based pricing can be higher at scale for token-heavy use cases; predictability depends on usage patterns.\n",
       "    - Open collaboration and community ecosystem weaker than Hugging Face in terms of open-source model/dataset sharing (perceived tradeoff for safety).\n",
       "    - Desktop integration (Cowork) is part of the Claude ecosystem but may introduce separate cost/management considerations for large teams.\n",
       "\n",
       "5) Competitive gaps and opportunities (what each could exploit or address)\n",
       "- Gaps in Hugging Face relative to Anthropic\n",
       "  - Safety and governance depth: While Enterprise Hub provides governance features, Anthropic’s safety-focused framing and long-context agent capabilities may outpace Hugging Face in highly regulated domains (e.g., healthcare, finance) where formal risk frameworks are required.\n",
       "  - On-prem / fully isolated deployments: While Enterprise Hub provides private storage, explicit on-prem or fully air-gapped deployments are not described. Opportunity to expand on-prem capabilities or more granular data residency controls.\n",
       "  - Deep safety tooling: Differentiating with built-in safety/steering tooling for end-users and governance policies could be expanded beyond audit logs and SSO.\n",
       "- Gaps in Anthropic relative to Hugging Face\n",
       "  - Open-source collaboration and community ecosystem: Hugging Face’s open weights, datasets, and community-driven Spaces are a powerful magnet for developers. Anthropic could explore more open collaboration or community tooling around safer-by-design models without compromising safety.\n",
       "  - Modularity and multi-modality ecosystem: Hugging Face’s breadth across models, datasets, and Spaces across modalities could serve as a broader platform if Anthropic expands model hosting or open adapters to integrate with more third-party tools.\n",
       "  - Pricing transparency and predictability: Token-based pricing is strong for certain usage profiles but can be opaque for larger teams. A clearer, tiered cost model with usage caps or bundled governance features could help large-scale adoption.\n",
       "\n",
       "6) Strategic recommendations (actionable guidance)\n",
       "- For Hugging Face\n",
       "  - Deepen enterprise governance and data residency options: Expand explicit on-premizable components or tighter data residency controls; improve auditability with configurable governance workflows for sensitive industries.\n",
       "  - Expand safety/compliance tooling: Build modular safety controls, model cards, and steerability policies integrated into the Enterprise Hub to complement existing SSO/audit features.\n",
       "  - Accelerate conversion of open-source momentum into enterprise scale: Offer clearer cost predictability for large-scale production use (e.g., tiered per-user plus predictable per-minute for endpoints, with caps and enterprise SLAs).\n",
       "  - Grow the Spaces ecosystem for enterprise-grade apps: Invest in approved templates for regulated domains (e.g., healthcare, finance) and provide security reviews for community apps.\n",
       "- For Anthropic\n",
       "  - Extend open collaboration to broaden ecosystem: Consider offering safer-by-design open templates, examples, or “AI safety kits” to enable developers to build responsibly while leveraging Claude in common workflows.\n",
       "  - Improve cost predictability and value realization: Provide more transparent enterprise pricing tiers, volume-based discounts, and better alignment between usage patterns (coding, agents, long-running tasks) and cost.\n",
       "  - Expand multi-cloud integration and on-prem options: While cross-cloud availability exists, explicit on-prem/offline deployment options could win contracts in regulated sectors requiring data sovereignty.\n",
       "  - Strengthen developer experience: Continue to simplify the Claude Developer Platform with richer tooling, code samples, and rapid-start guides for common enterprise workflows (customer support, education, healthcare).\n",
       "\n",
       "7) Quick synthesis by product category (practical takeaways)\n",
       "- Open-source collaboration and hosting\n",
       "  - Hugging Face is strongest in open collaboration, hosting of weights/datasets, and community-driven innovation.\n",
       "  - Anthropic prioritizes safety over open collaboration; limited emphasis on community hosting of models/datasets.\n",
       "- Production deployment and governance\n",
       "  - Hugging Face provides robust enterprise governance features (SSO, audit logs, private storage) and managed deployment via Endpoints.\n",
       "  - Anthropic emphasizes safety, long-context reasoning for agents, and enterprise-scale governance through its Enterprise plan.\n",
       "- Developer tooling and AI agents\n",
       "  - Hugging Face offers a broad ecosystem for models/datasets/spaces; Claude offers agentic capabilities but is more platform-centric around safety and enterprise workflows.\n",
       "  - Anthropic shines with Claude Developer Platform, Opus/Sonnet/Haiku variants, and desktop integration via Cowork for local file/tool access.\n",
       "- Pricing dynamics\n",
       "  - Hugging Face: Mixed model with per-user Enterprise pricing and pay-as-you-go Endpoints pricing.\n",
       "  - Anthropic: Token-based pricing across Opus/Sonnet/Haiku with discounts via caching/batching; subscription bundles (Max) and team/enterprise plans.\n",
       "\n",
       "8) Conclusion\n",
       "- Hugging Face and Anthropic serve overlapping but distinct appeals. Hugging Face is best for organizations seeking an open, collaborative, multi-modality ML platform with strong governance and scalable production deployment options. Anthropic is best for organizations prioritizing safety, interpretability, and enterprise-grade workflows with sophisticated agent tooling and cross-cloud compatibility.\n",
       "- For buyers, the choice depends on priority: open collaboration and ecosystem breadth (Hugging Face) vs safety-centric enterprise deployment with developer tooling and long-context agent capabilities (Anthropic). Consider hybrid strategies as appropriate (e.g., leveraging Hugging Face for model/dataset experimentation and Anthropic for safety-critical production workflows or agent-enabled tasks).\n",
       "\n",
       "9) Appendix / sources\n",
       "- Provided competitor data (JSON) detailing Hugging Face products (Hub, Inference Endpoints, Spaces, Enterprise Hub), pricing, target markets, and features.\n",
       "- Provided Anthropic data detailing Claude family (Claude, Claude Code, Cowork, Claude Developer Platform, Claude Opus/Sonnet/Haiku), pricing, target markets, and enterprise features.\n",
       "\n",
       "If you’d like, I can convert this into a slide-ready deck, or tailor the matrices to your preferred level of granularity (e.g., adding a SWOT per product or a one-page executive brief)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare competitors\n",
    "competitors = [\n",
    "    \"https://huggingface.co\",\n",
    "    \"https://anthropic.com\"\n",
    "]\n",
    "\n",
    "# Generate comparison report\n",
    "result = analyzer.generate_report(competitors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Access Structured Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hugging Face:\n",
      "  URL: https://huggingface.co\n",
      "  Products: 4\n",
      "  Key Features: 9\n",
      "  Pricing: PRO: $9 per user/month; Team: $20 per user/month; Enterprise: starting at $50 per user/month with cu...\n",
      "\n",
      "Anthropic:\n",
      "  URL: https://anthropic.com\n",
      "  Products: 10\n",
      "  Key Features: 10\n",
      "  Pricing: Opus 4.6 pricing: starting at $5 per million input tokens and $25 per million output tokens, with up...\n"
     ]
    }
   ],
   "source": [
    "# Access structured competitor data\n",
    "for comp in result[\"competitor_data\"]:\n",
    "    print(f\"\\n{comp.get('company_name', 'Unknown')}:\")\n",
    "    print(f\"  URL: {comp.get('url')}\")\n",
    "    print(f\"  Products: {len(comp.get('products', []))}\")\n",
    "    print(f\"  Key Features: {len(comp.get('key_features', []))}\")\n",
    "    if comp.get('pricing_info'):\n",
    "        print(f\"  Pricing: {comp.get('pricing_info')[:100]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
